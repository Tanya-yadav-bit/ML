{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCoeTOPKquVY"
      },
      "outputs": [],
      "source": [
        "#ONLY NEED TO CHANGE\n",
        "# 1️⃣ Model import\n",
        "# 2️⃣ Model definition + training\n",
        "# 3️⃣ Evaluation metric\n",
        "\n",
        "\n",
        "# Predict number/value\t---- Regression\n",
        "# Predict Yes / No\t    ---- Logistic\n",
        "# Predict 3+ classes\t  ---- RF / DT\n",
        "# “Leaderboard score matters”\t--- XGBoost\n",
        "# Dataset is very small\t----  KNN\n",
        "# Too many features\t    ----  PCA + Logistic\n",
        "# Classes imbalanced\t  ----  RF + F1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Random Forest(NEED CHANGE)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# FOR\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "# ``` |\n",
        "# | Binary classification |\n",
        "# ```python\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# ``` |\n",
        "# | Multiclass |\n",
        "# ```python\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# # OR keep RandomForestClassifier\n",
        "# ``` |\n",
        "# | Best Kaggle score |\n",
        "# ```python\n",
        "#from xgboost import XGBClassifier\n",
        "# ``` |\n",
        "# | Small dataset |\n",
        "# ```python\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# ``` |\n",
        "# | High dimension |\n",
        "# ```python\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# ``` |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- CONFIG (CHANGE THESE) --------\n",
        "TRAIN_PATH = \"/kaggle/input/mse-2-ai-201-b-aiml-c/train.csv\"\n",
        "TEST_PATH  = \"/kaggle/input/mse-2-ai-201-b-aiml-c/test.csv\"\n",
        "TARGET_COL = \"Class\"\n",
        "ID_COL     = \"id\"\n",
        "\n",
        "\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "F-sVTs5SrDWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== SHAPE =====\")\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)"
      ],
      "metadata": {
        "id": "rweUoG8LrI_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== COLUMNS =====\")\n",
        "print(train.columns)\n",
        "\n",
        "print(\"\\n===== DATA TYPES =====\")\n",
        "print(train.dtypes)\n",
        "\n",
        "print(\"\\n===== FIRST 10 ROWS =====\")\n",
        "print(train.head(10))\n",
        "\n",
        "print(\"\\n===== DESCRIPTIVE STATS =====\")\n",
        "print(train.describe(include=\"all\"))\n",
        "\n",
        "print(\"\\n===== MISSING VALUES =====\")\n",
        "print(train.isnull().sum())\n",
        "\n",
        "print(\"\\n===== TARGET VALUE COUNTS =====\")\n",
        "print(train[TARGET_COL].value_counts())"
      ],
      "metadata": {
        "id": "VmnynQK1rJ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#                 VISUALIZATION\n",
        "\n",
        "\n",
        "# Missing value heatmap\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(train.isnull(), cbar=False)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Target distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=train[TARGET_COL])\n",
        "plt.title(\"Target Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SWBFnR7OrSKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical countplots\n",
        "categorical_cols_full = train.select_dtypes(exclude=[np.number]).columns\n",
        "for col in categorical_cols_full:\n",
        "    #, ID_COL\n",
        "    if col not in [TARGET_COL, ID_COL]:\n",
        "        plt.figure(figsize=(6,4))\n",
        "        sns.countplot(x=train[col])\n",
        "        plt.title(f\"Countplot of {col}\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ihL5Dbv6rVFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for numeric columns\n",
        "numeric_cols_full = train.select_dtypes(include=[np.number]).columns\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.boxplot(data=train[numeric_cols_full], orient=\"h\")\n",
        "plt.title(\"Numeric Feature Boxplots\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ruj2htWerZM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(train[numeric_cols_full].corr(), cmap=\"coolwarm\", annot=False)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ddDSooKErb5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                 DATA CLEANING\n",
        "\n",
        "\n",
        "train = train.drop_duplicates()\n",
        "test  = test.drop_duplicates()\n",
        "\n",
        "train = train.dropna(subset=[TARGET_COL])\n",
        "\n",
        "X = train.drop([TARGET_COL,ID_COL], axis=1)\n",
        "y = train[TARGET_COL]\n",
        "\n",
        "# when  Your target column has strings ('A', 'B', maybe 'C')\n",
        "# XGBoost expects numbers (0, 1, 2, ...)\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# target_encoder = LabelEncoder()\n",
        "# y = target_encoder.fit_transform(y)\n",
        "\n",
        "# #as multiclass only for xg boost\n",
        "# num_classes = len(np.unique(y))\n",
        "\n",
        "#     ---------------------------------------------------------------\n",
        "\n",
        "test_ids = test[ID_COL]\n",
        "X_test   = test.drop(ID_COL, axis=1)"
      ],
      "metadata": {
        "id": "WEt_2CXLrhd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier removal (IQR)\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "Q1 = X[numeric_cols].quantile(0.25)\n",
        "Q3 = X[numeric_cols].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "mask = ~(\n",
        "    (X[numeric_cols] < (Q1 - 1.5*IQR)) |\n",
        "    (X[numeric_cols] > (Q3 + 1.5*IQR))\n",
        ").any(axis=1)\n",
        "\n",
        "X = X[mask]\n",
        "y = y[mask]\n"
      ],
      "metadata": {
        "id": "btHYoUMxrkoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Safe label encoding\n",
        "categorical_cols = X.select_dtypes(exclude=[np.number]).columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([X[col], X_test[col]], axis=0).astype(str)\n",
        "    le.fit(combined)\n",
        "    X[col]      = le.transform(X[col].astype(str))\n",
        "    X_test[col] = le.transform(X_test[col].astype(str))\n",
        "\n",
        "X      = X.fillna(X.median())\n",
        "X_test = X_test.fillna(X.median())"
      ],
      "metadata": {
        "id": "5yU2by4rrn7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                 TRAIN-TEST SPLIT\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "HAN1zeemrsu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                 HYPERPARAMETER TUNING\n",
        "\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [None, 10, 20],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UenH2Qw4ryDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#CHANGE ACCORDINGLy -GRID+GRID,MODEL.FIT\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    params,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "#REGREESION\n",
        "\n",
        "# model = LinearRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "#binary classification\n",
        "\n",
        "# model = LogisticRegression(max_iter=1000)\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "#Decision tree\n",
        "\n",
        "# model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "\n",
        "#XGBOOST\n",
        "# model = XGBClassifier(\n",
        "#     n_estimators=300,\n",
        "#     learning_rate=0.05,\n",
        "#     max_depth=6,\n",
        "#     objective=\"multi:softprob\",\n",
        "#     num_class=num_classes,\n",
        "#     eval_metric=\"mlogloss\",\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "#KNN\n",
        "\n",
        "# model = KNeighborsClassifier(n_neighbors=5)\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#PCA +loistics\n",
        "# pca = PCA(n_components=0.95)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_val   = pca.transform(X_val)\n",
        "# X_test  = pca.transform(X_test)\n",
        "\n",
        "# model = LogisticRegression(max_iter=1000)\n",
        "# model.fit(X_train, y_train)\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "#for xg boost\n",
        "#y_pred = np.argmax(best_model.predict(X_val), axis=1)\n",
        "#-----------------\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "gUr9cAmlq1Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== VALIDATION RESULTS =====\")\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "best_model.fit(X, y)\n"
      ],
      "metadata": {
        "id": "HHyY6jvvsAqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#     1) SUBMISSION WITH LABEL PREDICTIONS (C, CL, D)\n",
        "# ============================================================\n",
        "\n",
        "label_preds = best_model.predict(X_test)\n",
        "\n",
        "#for xg boost\n",
        "# label_preds = np.argmax(best_model.predict(X_test), axis=1)\n",
        "# label_preds = target_encoder.inverse_transform(label_preds)\n",
        "\n",
        "\n",
        "submission_labels = pd.DataFrame({\n",
        "    ID_COL: test_ids,\n",
        "    TARGET_COL: label_preds\n",
        "})\n",
        "\n",
        "submission_labels.to_csv(\"submission_labels.csv\", index=False)\n",
        "print(\"\\nSaved: submission_labels.csv\")\n",
        "\n",
        "# # ============================================================\n",
        "# #     2) SUBMISSION WITH PROBABILITIES (Status_C, Status_CL, Status_D)\n",
        "# # ============================================================\n",
        "\n",
        "# probs = best_model.predict_proba(X_test)\n",
        "\n",
        "# classes = list(best_model.classes_)  # e.g. ['C','CL','D']\n",
        "# required = [\"C\", \"CL\", \"D\"]          # match sample submission\n",
        "\n",
        "# final_probs = []\n",
        "# for cls in required:\n",
        "#     idx = classes.index(cls)\n",
        "#     final_probs.append(probs[:, idx])\n",
        "\n",
        "# submission_probs = pd.DataFrame({\n",
        "#     ID_COL: test_ids,\n",
        "#     \"Status_C\":  final_probs[0],\n",
        "#     \"Status_CL\": final_probs[1],\n",
        "#     \"Status_D\":  final_probs[2]\n",
        "# })\n",
        "\n",
        "# submission_probs.to_csv(\"submission_probabilities.csv\", index=False)\n",
        "# print(\"\\nSaved: submission_probabilities.csv\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "-owXJ8P9r43i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}