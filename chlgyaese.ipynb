{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzQIauIQpTn-"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "TRAIN_PATH = \"train.csv\"\n",
        "TEST_PATH  = \"test.csv\"\n",
        "TARGET     = \"Status\"\n",
        "ID_COL     = \"id\"\n",
        "\n",
        "\n",
        "# Load Data\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "\n",
        "train = train.dropna(subset=[TARGET])\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape :\", test.shape)"
      ],
      "metadata": {
        "id": "oE4uP9m7qEmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(train[TARGET].value_counts())\n",
        "print(\"\\nTarget distribution (ratio):\")\n",
        "print(train[TARGET].value_counts(normalize=True))\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "sns.countplot(x=train[TARGET])\n",
        "plt.title(\"Target Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.heatmap(train.isnull(), cbar=False)\n",
        "plt.title(\"Missing Values Overview\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a37XSVrbqBZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation\n",
        "num_cols = train.select_dtypes(include=\"number\").columns.drop(ID_COL, errors=\"ignore\")\n",
        "cat_cols = train.select_dtypes(exclude=\"number\").columns.drop(TARGET, errors=\"ignore\")\n",
        "\n",
        "print(\"\\nNumeric Feature Summary:\")\n",
        "display(train[num_cols].describe().T)\n",
        "\n",
        "for col in num_cols[:5]:\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.histplot(train[col], kde=True)\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.show()\n",
        "\n",
        "for col in num_cols[:3]:\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.boxplot(x=train[TARGET], y=train[col])\n",
        "    plt.title(f\"{col} vs {TARGET}\")\n",
        "    plt.show()\n",
        "\n",
        "if len(num_cols) > 1:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(train[num_cols].corr(), cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Numeric Feature Correlation\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nCategorical Cardinality:\")\n",
        "for col in cat_cols:\n",
        "    print(f\"{col}: {train[col].nunique()} unique values\")\n",
        "\n",
        "if len(cat_cols) > 0:\n",
        "    plt.figure(figsize=(6,3))\n",
        "    sns.countplot(data=train, x=cat_cols[0], hue=TARGET)\n",
        "    plt.xticks(rotation=30)\n",
        "    plt.title(f\"{cat_cols[0]} vs {TARGET}\")\n",
        "    plt.show()\n",
        "\n",
        "X = train.drop([TARGET, ID_COL], axis=1)\n",
        "y = train[TARGET]\n",
        "X_test = test.drop(ID_COL, axis=1)\n",
        "test_ids = test[ID_COL]\n"
      ],
      "metadata": {
        "id": "8se0ogZop-29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "n_classes = len(le.classes_)\n",
        "print(\"\\nClasses:\", list(le.classes_))\n",
        "print(\"Number of classes:\", n_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "JZZjCRk-p6hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ]), num_cols),\n",
        "\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_cols)\n",
        "])\n"
      ],
      "metadata": {
        "id": "xxXF71XHp24f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        multi_class=\"auto\"\n",
        "    ),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"RandomForest\": RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        random_state=42,\n",
        "        class_weight=\"balanced\"\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "1qVVowEfpzWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validate\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scores = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        (\"prep\", preprocess),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    preds = pipe.predict(X_val)\n",
        "    probs = pipe.predict_proba(X_val)\n",
        "\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    scores[name] = acc\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "HQmvplFSpxQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Binary classification -----\n",
        "    if n_classes == 2:\n",
        "        auc = roc_auc_score(y_val, probs[:, 1])\n",
        "        print(f\"ROC-AUC : {auc:.4f}\")\n",
        "\n",
        "        plt.figure(figsize=(4,3))\n",
        "        sns.histplot(probs[:, 1], bins=30)\n",
        "        plt.title(f\"{name} Validation Probabilities\")\n",
        "        plt.show()\n",
        "\n",
        "    # ----- Multi-class classification -----\n",
        "    else:\n",
        "        ll = log_loss(y_val, probs)\n",
        "        print(f\"Log Loss: {ll:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C45B-P9-pqks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Model\n",
        "best_name = max(scores, key=scores.get)\n",
        "best_model = models[best_name]\n",
        "\n",
        "print(f\"\\nBest model: {best_name}\")\n",
        "\n",
        "final_pipe = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", best_model)\n",
        "])\n",
        "\n",
        "final_pipe.fit(X, y)"
      ],
      "metadata": {
        "id": "5XQwFUmKpolm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Predictions\n",
        "test_preds = final_pipe.predict(X_test)\n",
        "test_preds_label = le.inverse_transform(test_preds)\n",
        "\n",
        "test_probs = final_pipe.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "wBZkgbi9plBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SUBMISSION (CLASS LABELS)\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test_ids,\n",
        "    TARGET: test_preds_label\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Saved submission.csv\")\n",
        "\n",
        "\n",
        "# SUBMISSION (PROBABILITIES)\n",
        "prob_cols = [f\"{TARGET}_{cls}\" for cls in le.classes_]\n",
        "\n",
        "prob_submission = pd.DataFrame(\n",
        "    test_probs,\n",
        "    columns=prob_cols\n",
        ")\n",
        "\n",
        "prob_submission.insert(0, ID_COL, test_ids)\n",
        "prob_submission.to_csv(\"submission_proba.csv\", index=False)\n",
        "\n",
        "print(\"Saved submission_proba.csv\")\n"
      ],
      "metadata": {
        "id": "rC_Gx8TZpbHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}